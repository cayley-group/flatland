{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distant-courage",
   "metadata": {},
   "source": [
    "## Structure solving as meta-optimization (demo)\n",
    "\n",
    "This is going to be so cool!\n",
    "\n",
    "In the work of Senior et al. (2019), Yang et al. (2020), and others, static optimization constraints are predicted then provided to a static, general purpose optimization algorithm (with some amount of manual tuning of optimization parameters to the specific task).\n",
    "\n",
    "Fascinatingly, there is a broad modern literature on the use of neural networks to learn to optimize. For example, Andrychowicz et al. (2016) demonstrate the learning of a domain-specific optimization algorithm that subsequently was shown to out-perform all of the best in class optimizers available for that problem (that had been a legacy of painstaking effort over more than a decade).\n",
    "\n",
    "This is amazing because there's the potential to learn better and better optimizers from data which can in turn save time and money for future work - but it's also quite interesting to think of how an optimizer might learn to become specialized to individual optimization problems (such as navigating the energy landscape of a protein structure).\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Folding_funnel_schematic.svg\" alt=\"Folding funnel schematic.svg\" height=\"480\" width=\"463\">\n",
    "\n",
    "(Image [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0) / [Thomas Splettstoesser](commons.wikimedia.org/wiki/User:Splette); [original](https://commons.wikimedia.org/wiki/File:Folding_funnel_schematic.svg#/media/File:Folding_funnel_schematic.svg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-champion",
   "metadata": {},
   "source": [
    "### Work in progress\n",
    "\n",
    "The plan is to modify the [GraphNetEncoder](https://github.com/google/jax-md/blob/master/jax_md/nn.py#L650) and [EnergyGraphNet](https://github.com/google/jax-md/blob/master/jax_md/energy.py#L944) from jax-md to also accept as input evolutionary data and not to predict a single energy value but to predict several things including:\n",
    "\n",
    "1. A future conformation,\n",
    "2. A distance matrix,\n",
    "3. Bond angles, and\n",
    "4. Compound interaction strengths\n",
    "\n",
    "The simplest way to include (1) in a loss seems to be to have one of the model outputs be a coordinate for each node that are passed to a conventional jax-md energy function which is then used to incentivized input conformations being mapped to output conformations with lower energy.\n",
    "\n",
    "It looks like (2) and (3) would be straightforward if the model returned edge representation in some form. It's possible to for now also accomplish (4) in this way.\n",
    "\n",
    "The philosophy regarding (4) is that when folding a new protein you could obtain its iteraction profile fairly easily and if your model was previously trained to use interaction profiles as a guide (in the same way as using evolutionary data as a guide) might then be able to solve the structure more easily. Succeeding with that means architecting the model in a way consistent with that use case.\n",
    "\n",
    "This might be done in a variety of ways. In the spirit of our learned optimizer, we might wish to learn an optimizer that not only minimizes energy but predicts conformations that are more and more consistent with interaction profiles with a set of compounds. To do this it seems we may need to run a simulator of those structure/compound interactions (which would be computationally expensive but not impossible, especially for important structures). The tendency of the learned energy minimizer to minimize energy could be fine-tuned based on the interactions of produced structures with compounds.\n",
    "\n",
    "Or, we might consider the compound interactions as simply a guide to better learning how to extract information from evolutionary data and ignore their predictions at structure inference time.\n",
    "\n",
    "Alternatively, we might consider compound-polymer interaction strengths as a type of input, like evolutionary data, that need to be correctly encoded but need not be predicted by the network - it simply is yet another kind of input information that can help the model learn to predict low-energy structures.\n",
    "\n",
    "It's possible we might want to synergize with the energy-predicting approach of jax-md given that the task of learning to predict structures of lower energy seems closely related to that of computing energies - so training node functions to compute partial energies might be nice pre-training for their learning to perform position updates that reduce energy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-kenya",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Ensure the most recent version of Flatland is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install git+git://github.com/cayley-group/flatland.git --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-butter",
   "metadata": {},
   "source": [
    "### Loading examples\n",
    "\n",
    "Here we use a [Tensorflow Datasets](https://github.com/tensorflow/datasets) definition of a dataset generated using the Flatland environment. This provides a simplified interface to returning a [tf.data](https://www.tensorflow.org/guide/data) Dataset which has a variety of convenient methods for handling the input example stream (e.g. for batching, shuffling, caching, and pre-fetching).\n",
    "\n",
    "Let's load an example from the \"flatland_mock\" dataset to see what the structure and data type of examples will be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identical-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/flatland_mock/0.0.1\n",
      "INFO:absl:Reusing dataset flatland_mock (/home/jupyter/tensorflow_datasets/flatland_mock/0.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset for split train, from /home/jupyter/tensorflow_datasets/flatland_mock/0.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import flatland.dataset\n",
    "\n",
    "ds = tfds.load('flatland_mock', split=\"train\")\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "\n",
    "ds = ds.cache().repeat()\n",
    "for example in tfds.as_numpy(ds):\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "falling-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa_sequence': array([1, 2, 0, 0, 0, 0, 0, 1, 1, 0], dtype=int32),\n",
       " 'alignments': <tf.RaggedTensor [[2, 2, 2, 0, 0, 2, 1, 2, 0, 0], [1, 1, 0, 2, 1, 1, 2, 1, 2, 0], [1, 1, 2, 0, 1, 1, 0, 2, 0, 2], [1, 0, 1, 1, 0, 2, 1, 1, 2, 2], [0, 2, 0, 1, 2, 0, 2, 2, 0, 0]]>,\n",
       " 'compound_affinity': array([0.00758087, 0.23774783, 0.37480316, 0.08547738, 0.93872553,\n",
       "        0.5524232 , 0.31635335, 0.12758023, 0.28242147, 0.44345865,\n",
       "        0.83017063, 0.4613364 , 0.84054464, 0.43620852, 0.8709514 ,\n",
       "        0.6868894 , 0.21353707, 0.21109186, 0.7294403 , 0.32652786,\n",
       "        0.06179944, 0.58756477, 0.2238007 , 0.78140414, 0.93743885,\n",
       "        0.10661111, 0.6824019 , 0.15397342, 0.7832685 , 0.7026999 ,\n",
       "        0.8029139 , 0.4829773 , 0.12657185, 0.747258  , 0.8097496 ,\n",
       "        0.5689918 , 0.63764423, 0.04804136, 0.73256326, 0.31102976,\n",
       "        0.8087152 , 0.9840257 , 0.9967061 , 0.8089805 , 0.6003544 ,\n",
       "        0.80616623, 0.522206  , 0.43120426, 0.13516551, 0.23430112,\n",
       "        0.69846284, 0.47294742, 0.9477825 , 0.7068705 , 0.48284954,\n",
       "        0.64980924, 0.5897207 , 0.2426636 , 0.85021144, 0.29388365,\n",
       "        0.9277244 , 0.873891  , 0.70024824, 0.94932336, 0.6804067 ,\n",
       "        0.15727842, 0.7097491 , 0.9129476 , 0.6253713 , 0.08636273,\n",
       "        0.8298653 , 0.15416978, 0.4825151 , 0.86737096, 0.62822294,\n",
       "        0.7527713 , 0.1943614 , 0.72496665, 0.9281688 , 0.16085744,\n",
       "        0.40142033, 0.12525153, 0.11444321, 0.99679106, 0.38071883,\n",
       "        0.9662188 , 0.41437078, 0.2691967 , 0.7680235 , 0.6999689 ,\n",
       "        0.74420625, 0.11362763, 0.6345952 , 0.28558457, 0.22216257,\n",
       "        0.13504934, 0.2529779 , 0.7651217 , 0.24367099, 0.16638312],\n",
       "       dtype=float32),\n",
       " 'solved_angles': array([0.30773067, 0.30883676, 0.8937048 , 0.03633691, 0.08487631,\n",
       "        0.43013212, 0.23460752, 0.34448144, 0.3287187 ], dtype=float32),\n",
       " 'solved_distances': array([0.93872786, 0.6540479 , 0.85461175, 0.11351407, 0.4506242 ,\n",
       "        0.29405695, 0.48170468, 0.0700336 , 0.61438483, 0.08047299,\n",
       "        0.07754292, 0.9855317 , 0.43563035, 0.66660905, 0.04452155,\n",
       "        0.37044123, 0.26875335, 0.11732685, 0.22737345, 0.5257386 ,\n",
       "        0.62657   , 0.00269602, 0.18164267, 0.10602209, 0.65164703,\n",
       "        0.36589602, 0.7666357 , 0.42564866, 0.794638  , 0.07127995,\n",
       "        0.5444798 , 0.59131175, 0.36892673, 0.03946656, 0.28349063,\n",
       "        0.39168787, 0.9184065 , 0.9700672 , 0.45571935, 0.00333469,\n",
       "        0.14187507, 0.7662337 , 0.23539351, 0.5946497 , 0.92767334,\n",
       "        0.4821984 , 0.83728135, 0.6116666 , 0.81440324, 0.42729756,\n",
       "        0.81250733, 0.33916357, 0.4989837 , 0.23412551, 0.67193663,\n",
       "        0.3944592 , 0.8018925 , 0.43721038, 0.13337618, 0.01936306,\n",
       "        0.65156156, 0.354352  , 0.5315772 , 0.21748732, 0.16353224,\n",
       "        0.06642021, 0.7310504 , 0.92696446, 0.72325164, 0.6523122 ,\n",
       "        0.9402377 , 0.4370314 , 0.34155267, 0.4042811 , 0.06460565,\n",
       "        0.72850627, 0.17969537, 0.6371526 , 0.44068208, 0.28705078,\n",
       "        0.6394626 , 0.36202693, 0.4056553 , 0.54251134, 0.28432614,\n",
       "        0.09490412, 0.74046886, 0.62322545, 0.30645496, 0.43935013,\n",
       "        0.5771984 , 0.6187322 , 0.44504   , 0.00546927, 0.08169147,\n",
       "        0.11140837, 0.25803965, 0.7441871 , 0.9171694 , 0.9759852 ],\n",
       "       dtype=float32),\n",
       " 'structure_energy': 0.19935934,\n",
       " 'structure_x': array([0.8291022 , 0.66525596, 0.99300843, 0.17532311, 0.97756076,\n",
       "        0.65190166, 0.9148779 , 0.11442716, 0.92032564, 0.17376485],\n",
       "       dtype=float32),\n",
       " 'structure_y': array([0.87287694, 0.04508143, 0.07940423, 0.2337335 , 0.6349673 ,\n",
       "        0.63391536, 0.9201641 , 0.7062284 , 0.268544  , 0.52811676],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-serial",
   "metadata": {},
   "source": [
    "## Train demo solver\n",
    "\n",
    "Here we have a wrapper to train the demo solver that currently only trains an energy predicting model but subsequently will transfer-learn this to predicting lower-energy structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flatland.train import train_demo_solver\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "params = train_demo_solver(num_training_steps=1,\n",
    "                           training_log_every=1,\n",
    "                           batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "english-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/flatland_mock/0.0.1\n",
      "INFO:absl:Reusing dataset flatland_mock (/home/jupyter/tensorflow_datasets/flatland_mock/0.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset for split train, from /home/jupyter/tensorflow_datasets/flatland_mock/0.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from flatland.train import demo_example_stream, graph_network_neighbor_list\n",
    "from flatland.train import OrigamiNet\n",
    "from jax_md import space\n",
    "from functools import partial\n",
    "\n",
    "box_size = 10.862\n",
    "batch_size = 16\n",
    "\n",
    "iter_examples = demo_example_stream(\n",
    "  batch_size=batch_size, split=\"train\")\n",
    "\n",
    "positions, energies, forces = next(iter_examples)\n",
    "_, polymer_length, polymer_dimensions = positions.shape\n",
    "\n",
    "displacement, shift = space.periodic(box_size)\n",
    "\n",
    "neighbor_fn, init_fn, apply_fn = graph_network_neighbor_list(\n",
    "  network=OrigamiNet,\n",
    "  displacement_fn=displacement,\n",
    "  box_size=box_size,\n",
    "  polymer_length=polymer_length,\n",
    "  polymer_dimensions=polymer_dimensions,\n",
    "  r_cutoff=3.0,\n",
    "  dr_threshold=0.0)\n",
    "\n",
    "neighbor = neighbor_fn(positions[0], extra_capacity=6)\n",
    "\n",
    "structure_fn = partial(apply_fn, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "structure = structure_fn(positions[0], neighbor)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "equivalent-welsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-125.68002 , -180.35202 ,   75.57445 ,   37.897186,\n",
       "               72.177246,  145.60895 , -163.79515 ,   23.409634,\n",
       "               30.021103,  101.55815 ,   38.034508, -137.15297 ,\n",
       "             -132.84296 , -161.73619 ,   99.6241  ,  -55.685173,\n",
       "               49.254753,   70.4132  ,  -14.434248,  131.40115 ],            dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "physical-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# A polymer of length 10 and dimension 2\n",
    "structure.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "arabic-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%timeit structure_fn(next(iter_examples)[0][0], neighbor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-priority",
   "metadata": {},
   "source": [
    "## Long auto-regressive search\n",
    "\n",
    "Here we will provide some minimal experimentation with using the model to actually optimize a structure by simply repeatedly applying the structure minimizer. We'll characterize what happens to the energy - e.g. does it consistently go down over time or does it diverge after a certain length of such a \"rollout\"?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WIP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-vacation",
   "metadata": {},
   "source": [
    "## Genetic + short auto-regressive\n",
    "\n",
    "Presuming the previous won't be stable under long-rollouts, we'll use the previous method only over somewhat short rollouts (for the horizon over which these are stable) in conjunction with an evolutionary optimization approach to progressively determining better and better optimization starting points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WIP\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
